{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generate pseudo-label from CT scanned images\n",
    "We will detect bounding boxes of the sand grain images and then try to detect regions of interest within those boxes. The detected objects will work as pseudo-label for DL model training."
   ],
   "id": "7a4d83c3914d885f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Author:** _Ashiqur Rahman_\n",
    "**Institute:** _Norther Illinois University_\n",
    "**GitHub:** _@ashiqur-rony_"
   ],
   "id": "a6be94762df16154"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "id": "5f03da3da7cd7df5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-21T01:20:37.828843Z",
     "start_time": "2025-06-21T01:20:37.703740Z"
    }
   },
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from dask.array.overlap import boundaries\n",
    "from holoviews.plotting.bokeh.styles import alpha\n",
    "from mypy.checkexpr import annotations\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.morphology import closing, remove_small_objects, remove_small_holes\n",
    "import skimage.morphology as morphology\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as mcolors\n",
    "from skimage.morphology import closing\n",
    "from skimage.segmentation import clear_border\n",
    "from spyder_kernels.utils.nsview import get_object_attrs\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import binary_closing, binary_fill_holes, generate_binary_structure\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from sympy.matrices.expressions.blockmatrix import bounds"
   ],
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Defining Functions"
   ],
   "id": "af4958cb0427fe2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Utility Functions"
   ],
   "id": "28475447b362f85f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.029416Z",
     "start_time": "2025-06-21T00:57:10.025533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _decompose_size(size, kernel_size=3):\n",
    "    \"\"\"Determine number of repeated iterations for a `kernel_size` kernel.\n",
    "\n",
    "    Returns how many repeated morphology operations with an element of size\n",
    "    `kernel_size` is equivalent to a morphology with a single kernel of size\n",
    "    `n`.\n",
    "\n",
    "    \"\"\"\n",
    "    if kernel_size % 2 != 1:\n",
    "        raise ValueError(\"only odd length kernel_size is supported\")\n",
    "    return 1 + (size - kernel_size) // (kernel_size - 1)"
   ],
   "id": "3457eb2f643ef2f0",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.056654Z",
     "start_time": "2025-06-21T00:57:10.051646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def footprint_rectangle(shape, *, dtype=np.uint8, decomposition=None):\n",
    "    \"\"\"Generate a rectangular or hyper-rectangular footprint.\n",
    "\n",
    "    Generates, depending on the length and dimensions requested with `shape`,\n",
    "    a square, rectangle, cube, cuboid, or even higher-dimensional versions\n",
    "    of these shapes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : tuple[int, ...]\n",
    "        The length of the footprint in each dimension. The length of the\n",
    "        sequence determines the number of dimensions of the footprint.\n",
    "    dtype : data-type, optional\n",
    "        The data type of the footprint.\n",
    "    decomposition : {None, 'separable', 'sequence'}, optional\n",
    "        If None, a single array is returned. For 'sequence', a tuple of smaller\n",
    "        footprints is returned. Applying this series of smaller footprints will\n",
    "        give an identical result to a single, larger footprint, but often with\n",
    "        better computational performance. See Notes for more details.\n",
    "        With 'separable', this function uses separable 1D footprints for each\n",
    "        axis. Whether 'sequence' or 'separable' is computationally faster may\n",
    "        be architecture-dependent.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    footprint : array or tuple[tuple[ndarray, int], ...]\n",
    "        A footprint consisting only of ones, i.e. every pixel belongs to the\n",
    "        neighborhood. When `decomposition` is None, this is just an array.\n",
    "        Otherwise, this will be a tuple whose length is equal to the number of\n",
    "        unique structuring elements to apply (see Examples for more detail).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import skimage as ski\n",
    "    >>> ski.morphology.footprint_rectangle((3, 5))\n",
    "    array([[1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1]], dtype=uint8)\n",
    "\n",
    "    Decomposition will return multiple footprints that combine into a simple\n",
    "    footprint of the requested shape.\n",
    "\n",
    "    >>> ski.morphology.footprint_rectangle((9, 9), decomposition=\"sequence\")\n",
    "    ((array([[1, 1, 1],\n",
    "             [1, 1, 1],\n",
    "             [1, 1, 1]], dtype=uint8),\n",
    "      4),)\n",
    "\n",
    "    `\"sequence\"` makes sure that the decomposition only returns 1D footprints.\n",
    "\n",
    "    >>> ski.morphology.footprint_rectangle((3, 5), decomposition=\"separable\")\n",
    "    ((array([[1],\n",
    "             [1],\n",
    "             [1]], dtype=uint8),\n",
    "      1),\n",
    "     (array([[1, 1, 1, 1, 1]], dtype=uint8), 1))\n",
    "\n",
    "    Generate a 5-dimensional hypercube with 3 samples in each dimension\n",
    "\n",
    "    >>> ski.morphology.footprint_rectangle((3,) * 5).shape\n",
    "    (3, 3, 3, 3, 3)\n",
    "    \"\"\"\n",
    "    has_even_width = any(width % 2 == 0 for width in shape)\n",
    "    if decomposition == \"sequence\" and has_even_width:\n",
    "        decomposition = \"sequence_fallback\"\n",
    "    \n",
    "    def partial_footprint(dim, width):\n",
    "        shape_ = (1,) * dim + (width,) + (1,) * (len(shape) - dim - 1)\n",
    "        fp = (np.ones(shape_, dtype=dtype), 1)\n",
    "        return fp\n",
    "\n",
    "    if decomposition is None:\n",
    "        footprint = np.ones(shape, dtype=dtype)\n",
    "\n",
    "    elif decomposition in (\"separable\", \"sequence_fallback\"):\n",
    "        footprint = tuple(\n",
    "            partial_footprint(dim, width) for dim, width in enumerate(shape)\n",
    "        )\n",
    "\n",
    "    elif decomposition == \"sequence\":\n",
    "        min_width = min(shape)\n",
    "        sq_reps = _decompose_size(min_width, 3)\n",
    "        footprint = [(np.ones((3,) * len(shape), dtype=dtype), sq_reps)]\n",
    "        for dim, width in enumerate(shape):\n",
    "            if width > min_width:\n",
    "                nextra = width - min_width + 1\n",
    "                component = partial_footprint(dim, nextra)\n",
    "                footprint.append(component)\n",
    "        footprint = tuple(footprint)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized decomposition: {decomposition}\")\n",
    "\n",
    "    return footprint\n",
    "    "
   ],
   "id": "8fa2df46c0fcc14f",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Region Growing Functions\n",
    "We experimented with different types of region growing functions."
   ],
   "id": "2984c847aec3ccee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.082135Z",
     "start_time": "2025-06-21T00:57:10.073555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_regions_within_mask(image, mask, tolerance=0):\n",
    "    \"\"\"\n",
    "    Find regions of interest within the mask.\n",
    "    Parameters:\n",
    "        :image: numpy array, the input image\n",
    "        :mask: numpy array, the mask of the bounding boxes\n",
    "        :tolerance: int, the tolerance for pixel value difference when checking neighbors\n",
    "    Returns:\n",
    "        :regions: list of lists, each list contains the coordinates of the pixels in a region\n",
    "    \"\"\"\n",
    "    regions = []\n",
    "    visited = np.zeros_like(image, dtype=bool)\n",
    "    \n",
    "    # Get the coordinates of the mask\n",
    "    coords = np.column_stack(np.where(mask))\n",
    "    \n",
    "    # Get the pixel value to compare with\n",
    "    pixel_value = image[coords[0][0], coords[0][1]]\n",
    "    found_different_pixel = False\n",
    "    # Iterate through the mask to find the first pixel that is not part of the mask\n",
    "    c = 0\n",
    "    while c in range(len(coords)) and not found_different_pixel:\n",
    "        row, col = coords[c]\n",
    "        c += 1\n",
    "        pixel_value = image[row, col]\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i in range (image.shape[0] - row) and not found_different_pixel:\n",
    "            while j in range (image.shape[1] - col) and not found_different_pixel:\n",
    "                if row + i < image.shape[0] and col + j < image.shape[1]:\n",
    "                    if not mask[row + i, col + j] and image[row, col] != image[row + i, col + j]:\n",
    "                        pixel_value = image[row + i, col + j]\n",
    "                        found_different_pixel = True\n",
    "                j += 1\n",
    "            i += 1\n",
    "                        \n",
    "    within_mask = False\n",
    "    queue = []\n",
    "    \n",
    "    # Iterate through each pixel in the image and when we found the start of a mask,\n",
    "    # we will start a BFS to find all the connected pixels with the same pixel value.\n",
    "    # This will help us to find the regions of interest inside the bounding boxes.\n",
    "    \n",
    "    for row in range(image.shape[0]):\n",
    "        for col in range(image.shape[1]):\n",
    "            if mask[row, col] and not visited[row, col]:\n",
    "                # We flip the within_mask flag to check if the pixel is within the mask or not\n",
    "                within_mask = not within_mask\n",
    "                \n",
    "            current_region = []\n",
    "            \n",
    "            # If we are within a mask or the pixel is part of the mask border, add it to the queue.\n",
    "            if within_mask or mask[row, col]:\n",
    "                queue = [(row, col)]\n",
    "            \n",
    "            while queue:\n",
    "                r, c = queue.pop(0)\n",
    "                if visited[r, c]:\n",
    "                    continue\n",
    "                \n",
    "                visited[r, c] = True\n",
    "                current_region.append((r, c))\n",
    "                \n",
    "                # Check neighbors in a 2x2 grid around the pixel\n",
    "                for dr in [-2, -1, 0, 1, 2]:\n",
    "                    for dc in [-2, -1, 0, 1, 2]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < image.shape[0] and \n",
    "                            0 <= nc < image.shape[1] and \n",
    "                            not visited[nr, nc] and \n",
    "                            within_mask and\n",
    "                            abs(int(image[nr, nc]) - pixel_value) <= tolerance):\n",
    "                            queue.append((nr, nc))\n",
    "            \n",
    "            if current_region:\n",
    "                regions.append(current_region)\n",
    "    \n",
    "    return regions"
   ],
   "id": "91d1596fdb62405f",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.088755Z",
     "start_time": "2025-06-21T00:57:10.082135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each pixel of the image we will check if it is inside the combined mask.\n",
    "# If it is, we will set a flag for the pixel and start a BFS to flag all the nearby pixels with same pixel values.\n",
    "# This will help us to find the regions of interest inside the bounding boxes.\n",
    "\n",
    "def find_regions_of_interest(image, mask, tolerance=0):\n",
    "    \"\"\"\n",
    "    Find regions of interest inside the bounding boxes.\n",
    "    Parameters:\n",
    "        :image: numpy array, the input image\n",
    "        :mask: numpy array, the mask of the bounding boxes\n",
    "        :tolerance: int, the tolerance for pixel value difference when checking neighbors\n",
    "    Returns:\n",
    "        :regions: list of lists, each list contains the coordinates of the pixels in a region\n",
    "    \"\"\"\n",
    "    regions = []\n",
    "    visited = np.zeros_like(image, dtype=bool)\n",
    "    \n",
    "    # Get the coordinates of the mask\n",
    "    coords = np.column_stack(np.where(mask))\n",
    "    \n",
    "    # Iterate through each pixel in the image and when we found the start of a mask,\n",
    "    # we will start a BFS to find all the connected pixels with the same pixel value.\n",
    "    # This will help us to find the regions of interest inside the bounding boxes.\n",
    "    \n",
    "    for row in range(image.shape[0]):\n",
    "        for col in range(image.shape[1]):\n",
    "            if mask[row, col] and not visited[row, col]:\n",
    "                # To avoid the boundary, we will take the pixel value to the right until current pixel\n",
    "                # and the pixel value to the right are the same.\n",
    "                # Once we find that we will use current pixel value.\n",
    "                \n",
    "                pixel_value = image[row, col]\n",
    "                found_different_pixel = False\n",
    "                \n",
    "                for i in range (image.shape[0] - row):\n",
    "                    for j in range (image.shape[1] - col):\n",
    "                        if row + i < image.shape[0] and col + j < image.shape[1]:\n",
    "                            if not mask[row + i, col + j] and image[row, col] != image[row + i, col + j]:\n",
    "                                pixel_value = image[row + i, col + j]\n",
    "                                found_different_pixel = True\n",
    "                                break\n",
    "                        if found_different_pixel:\n",
    "                            break\n",
    "                    if not found_different_pixel:\n",
    "                        break\n",
    "                \n",
    "                current_region = []\n",
    "                queue = [(row, col)]\n",
    "                \n",
    "                while queue:\n",
    "                    r, c = queue.pop(0)\n",
    "                    if visited[r, c]:\n",
    "                        continue\n",
    "                    \n",
    "                    visited[r, c] = True\n",
    "                    current_region.append((r, c))\n",
    "                    \n",
    "                    # Check neighbors in a 2x2 grid around the pixel\n",
    "                    for dr in [-2, -1, 0, 1, 2]:\n",
    "                        for dc in [-2, -1, 0, 1, 2]:\n",
    "                            if dr == 0 and dc == 0:\n",
    "                                continue\n",
    "                            nr, nc = r + dr, c + dc\n",
    "                            if (0 <= nr < image.shape[0] and \n",
    "                                0 <= nc < image.shape[1] and \n",
    "                                not visited[nr, nc] and \n",
    "                                abs(int(image[nr, nc]) - pixel_value) <= tolerance):\n",
    "                                queue.append((nr, nc))\n",
    "                \n",
    "                if current_region:\n",
    "                    regions.append(current_region)\n",
    "    \n",
    "    return regions"
   ],
   "id": "cc5a4ab03e1d3c96",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.101642Z",
     "start_time": "2025-06-21T00:57:10.096498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_regions_within_boundaries(image, mask):\n",
    "    \"\"\"\n",
    "    Finds all contiguous regions of pixels that are located *within* the\n",
    "    boundaries defined by the `mask`. This version performs a geometric\n",
    "    fill. The values from the `image` are not used for region segmentation\n",
    "    itself, only the `mask` defines what is a boundary and what is interior.\n",
    "\n",
    "    Improvements over the original approach:\n",
    "    1.  Seed Pixel Selection: Identifies seed pixels for BFS that are\n",
    "        definitively *inside* the boundary (i.e., `not mask[pixel]`)\n",
    "        and adjacent to a boundary pixel.\n",
    "    2.  BFS Logic: Performs a Breadth-First Search (BFS) that expands\n",
    "        as long as pixels are within image bounds, *not* part of the `mask`,\n",
    "        and not yet visited by any fill operation.\n",
    "    3.  Region Content: Ensures that only non-mask (interior) pixels are\n",
    "        included in the found regions.\n",
    "    4.  Efficiency: Uses `collections.deque` for efficient queue operations in BFS.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy array, the input image. Not directly used for segmentation logic\n",
    "               in this version, but its shape is implicitly assumed to match the mask's.\n",
    "               Provided for API compatibility with the original function.\n",
    "        mask: numpy array (boolean or 0/1), where True/1 indicates a boundary pixel.\n",
    "              Shape should be (rows, cols).\n",
    "    Returns:\n",
    "        regions: A list of lists. Each inner list contains (row, col) tuples\n",
    "                 for pixels belonging to a distinct enclosed region.\n",
    "    \"\"\"\n",
    "\n",
    "    if mask.dtype != bool:\n",
    "        mask = mask.astype(bool) # Ensure mask is boolean\n",
    "\n",
    "    # Get dimensions from the mask\n",
    "    rows, cols = mask.shape\n",
    "    \n",
    "    # visited_fill tracks non-mask pixels that have already been assigned to a region.\n",
    "    visited_fill = np.zeros_like(mask, dtype=bool)\n",
    "    regions = []\n",
    "\n",
    "    # Iterate over each pixel to find boundary pixels.\n",
    "    # When a boundary pixel is found, we look for an adjacent non-boundary,\n",
    "    # unvisited pixel to start a new region fill.\n",
    "    for r_boundary in range(rows):\n",
    "        for c_boundary in range(cols):\n",
    "            # Check if the current pixel is part of a boundary\n",
    "            if mask[r_boundary, c_boundary]:\n",
    "                # Explore its 4-connected neighbors to find a seed pixel.\n",
    "                # A seed pixel must be:\n",
    "                # 1. Inside the image bounds.\n",
    "                # 2. NOT a boundary pixel itself (i.e., `not mask[seed_r, seed_c]`).\n",
    "                # 3. Not already part of a previously filled region.\n",
    "                for dr_seed, dc_seed in [(-1, 0), (1, 0), (0, -1), (0, 1)]: # 4-connectivity\n",
    "                    \n",
    "                    nr_potential_seed, nc_potential_seed = r_boundary + dr_seed, c_boundary + dc_seed\n",
    "\n",
    "                    # Check bounds for the potential seed\n",
    "                    if 0 <= nr_potential_seed < rows and 0 <= nc_potential_seed < cols:\n",
    "                        # Check if it's an interior pixel and not yet visited\n",
    "                        if not mask[nr_potential_seed, nc_potential_seed] and \\\n",
    "                           not visited_fill[nr_potential_seed, nc_potential_seed]:\n",
    "                            \n",
    "                            # Found a valid seed pixel. Start a BFS to find the entire region.\n",
    "                            current_region_coords = []\n",
    "                            q_fill = deque([(nr_potential_seed, nc_potential_seed)])\n",
    "                            \n",
    "                            # Mark the seed pixel as visited immediately to prevent re-processing.\n",
    "                            visited_fill[nr_potential_seed, nc_potential_seed] = True\n",
    "                            \n",
    "                            while q_fill:\n",
    "                                r_curr, c_curr = q_fill.popleft()\n",
    "                                current_region_coords.append((r_curr, c_curr))\n",
    "\n",
    "                                # Explore 4-connected neighbors for the fill.\n",
    "                                for dr_fill, dc_fill in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                                    next_r, next_c = r_curr + dr_fill, c_curr + dc_fill\n",
    "\n",
    "                                    # Check bounds for the neighbor\n",
    "                                    if 0 <= next_r < rows and 0 <= next_c < cols:\n",
    "                                        # If the neighbor is within bounds, not yet visited,\n",
    "                                        # and is an interior pixel (not a boundary),\n",
    "                                        # add it to the queue and mark as visited.\n",
    "                                        if not visited_fill[next_r, next_c] and \\\n",
    "                                           not mask[next_r, next_c]:\n",
    "                                            visited_fill[next_r, next_c] = True\n",
    "                                            q_fill.append((next_r, next_c))\n",
    "                            \n",
    "                            # If the region has pixels, add it to the list of regions.\n",
    "                            if current_region_coords:\n",
    "                                regions.append(current_region_coords)\n",
    "    return regions"
   ],
   "id": "6e83eacb506fd4a7",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.116848Z",
     "start_time": "2025-06-21T00:57:10.109330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_intensity_regions_within_boundaries(image, mask):\n",
    "    \"\"\"\n",
    "    Finds contiguous regions of similar pixel intensity that are located\n",
    "    *within* the boundaries defined by the `mask`.\n",
    "\n",
    "    This version:\n",
    "    1.  Identifies seed pixels that are *inside* the boundary (not mask)\n",
    "        and not yet part of a found region.\n",
    "    2.  For each seed, it records its pixel intensity from the `image`.\n",
    "    3.  Performs a Breadth-First Search (BFS) that expands as long as\n",
    "        neighboring pixels are:\n",
    "        a. Within image bounds.\n",
    "        b. Not part of the `mask`.\n",
    "        c. Not yet visited.\n",
    "        d. Have the *same intensity* as the seed pixel.\n",
    "    4.  Ensures only non-mask pixels are included in the regions.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy array (2D, grayscale). Pixel intensities from this image\n",
    "               are used to define region homogeneity.\n",
    "        mask: numpy array (boolean or 0/1), where True/1 indicates a boundary pixel.\n",
    "              Shape should be (rows, cols) and match `image.shape`.\n",
    "    Returns:\n",
    "        regions: A list of lists. Each inner list contains (row, col) tuples\n",
    "                 for pixels belonging to a distinct intensity-based region\n",
    "                 within the boundaries.\n",
    "    \"\"\"\n",
    "\n",
    "    if image.ndim != 2:\n",
    "        raise ValueError(\"Image must be 2D (grayscale).\")\n",
    "    if image.shape != mask.shape:\n",
    "        raise ValueError(\"Image and mask must have the same dimensions.\")\n",
    "\n",
    "    if mask.dtype != bool:\n",
    "        mask = mask.astype(bool)\n",
    "\n",
    "    rows, cols = image.shape\n",
    "    \n",
    "    # visited_pixels tracks pixels already assigned to a region.\n",
    "    visited_pixels = np.zeros_like(mask, dtype=bool)\n",
    "    found_regions = []\n",
    "\n",
    "    for r_boundary in range(rows):\n",
    "        for c_boundary in range(cols):\n",
    "            if mask[r_boundary, c_boundary]: # It's a boundary pixel\n",
    "                # Check its 4-connected neighbors to find a potential seed\n",
    "                for dr_seed, dc_seed in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                    \n",
    "                    nr_potential_seed, nc_potential_seed = r_boundary + dr_seed, c_boundary + dc_seed\n",
    "\n",
    "                    if 0 <= nr_potential_seed < rows and 0 <= nc_potential_seed < cols:\n",
    "                        # Seed must be: not a mask pixel AND not yet visited\n",
    "                        if not mask[nr_potential_seed, nc_potential_seed] and \\\n",
    "                           not visited_pixels[nr_potential_seed, nc_potential_seed]:\n",
    "                            \n",
    "                            current_seed_r, current_seed_c = nr_potential_seed, nc_potential_seed\n",
    "                            seed_intensity = image[current_seed_r, current_seed_c]\n",
    "                            \n",
    "                            current_region_coords = []\n",
    "                            q_bfs = deque([(current_seed_r, current_seed_c)])\n",
    "                            \n",
    "                            # Mark the exact seed pixel as visited\n",
    "                            visited_pixels[current_seed_r, current_seed_c] = True\n",
    "                            \n",
    "                            while q_bfs:\n",
    "                                r_curr, c_curr = q_bfs.popleft()\n",
    "                                current_region_coords.append((r_curr, c_curr))\n",
    "\n",
    "                                for dr_bfs, dc_bfs in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                                    next_r, next_c = r_curr + dr_bfs, c_curr + dc_bfs\n",
    "\n",
    "                                    if 0 <= next_r < rows and 0 <= next_c < cols:\n",
    "                                        if not visited_pixels[next_r, next_c] and \\\n",
    "                                           not mask[next_r, next_c] and \\\n",
    "                                           image[next_r, next_c] == seed_intensity: # Key check\n",
    "                                            \n",
    "                                            visited_pixels[next_r, next_c] = True\n",
    "                                            q_bfs.append((next_r, next_c))\n",
    "                            \n",
    "                            if current_region_coords:\n",
    "                                found_regions.append(current_region_coords)\n",
    "    return found_regions"
   ],
   "id": "e5635f69ee100103",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.130052Z",
     "start_time": "2025-06-21T00:57:10.124575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_intensity_range_within_boundaries(image, mask, intensity_tolerance=5):\n",
    "    \"\"\"\n",
    "    Finds contiguous regions of similar pixel intensity that are located\n",
    "    *within* the boundaries defined by the `mask`, allowing for a specified\n",
    "    intensity tolerance. Seed finding is optimized to start from pixels\n",
    "    adjacent to boundaries.\n",
    "\n",
    "    This version:\n",
    "    1.  Identifies seed pixels by checking neighbors of `mask` (boundary) pixels.\n",
    "        A seed must be *inside* the boundary (not mask) and not yet visited.\n",
    "    2.  For each seed, it records its pixel intensity from the `image`.\n",
    "    3.  Performs a Breadth-First Search (BFS) that expands as long as\n",
    "        neighboring pixels are:\n",
    "        a. Within image bounds.\n",
    "        b. Not part of the `mask`.\n",
    "        c. Not yet visited.\n",
    "        d. Have an intensity within `intensity_tolerance` of the seed pixel's intensity.\n",
    "    4.  Ensures only non-mask pixels are included in the regions.\n",
    "\n",
    "    Parameters:\n",
    "        image: numpy array (2D, grayscale). Pixel intensities from this image\n",
    "               are used to define region homogeneity. Assumed to be of a\n",
    "               numeric type (e.g., uint8, int16, float).\n",
    "        mask: numpy array (boolean or 0/1), where True/1 indicates a boundary pixel.\n",
    "              Shape should be (rows, cols) and match `image.shape`.\n",
    "        intensity_tolerance: int, the maximum allowed absolute difference\n",
    "                             between a pixel's intensity and the seed pixel's\n",
    "                             intensity for it to be included in the region.\n",
    "                             Default is 5.\n",
    "    Returns:\n",
    "        regions: A list of lists. Each inner list contains (row, col) tuples\n",
    "                 for pixels belonging to a distinct intensity-based region\n",
    "                 within the boundaries.\n",
    "    \"\"\"\n",
    "\n",
    "    if image.ndim != 2:\n",
    "        raise ValueError(\"Image must be 2D (grayscale).\")\n",
    "    if image.shape != mask.shape:\n",
    "        raise ValueError(\"Image and mask must have the same dimensions.\")\n",
    "\n",
    "    if mask.dtype != bool:\n",
    "        mask = mask.astype(bool)\n",
    "\n",
    "    rows, cols = image.shape\n",
    "    \n",
    "    # visited_pixels tracks pixels already assigned to a region.\n",
    "    visited_pixels = np.zeros_like(mask, dtype=bool)\n",
    "    found_regions = []\n",
    "\n",
    "    # Iterate through all pixels to find boundary pixels\n",
    "    for r_boundary in range(rows):\n",
    "        for c_boundary in range(cols):\n",
    "            # If it's a boundary pixel, check its neighbors for potential seeds\n",
    "            if mask[r_boundary, c_boundary]:\n",
    "                # Explore 4-connected neighbors of the boundary pixel\n",
    "                for dr_seed, dc_seed in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                    \n",
    "                    current_seed_r, current_seed_c = r_boundary + dr_seed, c_boundary + dc_seed\n",
    "\n",
    "                    # Check if the potential seed is within bounds\n",
    "                    if 0 <= current_seed_r < rows and 0 <= current_seed_c < cols:\n",
    "                        # Seed must be: not a mask pixel AND not yet visited\n",
    "                        if not mask[current_seed_r, current_seed_c] and \\\n",
    "                           not visited_pixels[current_seed_r, current_seed_c]:\n",
    "                            \n",
    "                            # Found a valid seed pixel.\n",
    "                            # It's crucial to handle image dtype correctly for subtraction.\n",
    "                            seed_intensity = int(image[current_seed_r, current_seed_c]) \n",
    "                            \n",
    "                            current_region_coords = []\n",
    "                            q_bfs = deque([(current_seed_r, current_seed_c)])\n",
    "                            \n",
    "                            # Mark the exact seed pixel as visited\n",
    "                            visited_pixels[current_seed_r, current_seed_c] = True\n",
    "                            \n",
    "                            while q_bfs:\n",
    "                                r_curr, c_curr = q_bfs.popleft()\n",
    "                                current_region_coords.append((r_curr, c_curr))\n",
    "\n",
    "                                # Explore 4-connected neighbors for BFS expansion\n",
    "                                for dr_bfs, dc_bfs in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                                    next_r, next_c = r_curr + dr_bfs, c_curr + dc_bfs\n",
    "\n",
    "                                    if 0 <= next_r < rows and 0 <= next_c < cols:\n",
    "                                        # Check if neighbor is valid for region\n",
    "                                        if not visited_pixels[next_r, next_c] and \\\n",
    "                                           not mask[next_r, next_c]:\n",
    "                                            \n",
    "                                            current_pixel_intensity = int(image[next_r, next_c])\n",
    "                                            # Check intensity tolerance\n",
    "                                            if abs(current_pixel_intensity - seed_intensity) <= intensity_tolerance:\n",
    "                                                visited_pixels[next_r, next_c] = True\n",
    "                                                q_bfs.append((next_r, next_c))\n",
    "                            \n",
    "                            if current_region_coords:\n",
    "                                found_regions.append(current_region_coords)\n",
    "    return found_regions"
   ],
   "id": "67bebd48006fb9da",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.141912Z",
     "start_time": "2025-06-21T00:57:10.138870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fill_gapped_objects(binary_image_array: np.ndarray, \n",
    "                        closing_iterations: int = 1, \n",
    "                        connectivity: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sets all pixels within white boundaries to True in a binary NumPy array,\n",
    "    attempting to close gaps in boundaries first using morphological closing,\n",
    "    and then performing hole filling.\n",
    "\n",
    "    Args:\n",
    "        binary_image_array: A 2D NumPy array where True represents white pixels\n",
    "                            (including boundaries and object interiors if any) \n",
    "                            and False represents black pixels. The function will\n",
    "                            convert it to a boolean array if it's not already.\n",
    "        closing_iterations: Number of iterations for the binary closing operation.\n",
    "                            A larger number of iterations can close larger gaps\n",
    "                            but may also distort the shapes more or merge very\n",
    "                            close objects. Start with 1 or 2 for small gaps.\n",
    "        connectivity: Defines the neighborhood for morphological operations (and hole filling).\n",
    "                      For a 2D image (which this function expects):\n",
    "                      - 1 creates a 4-connected structuring element (diamond shape: \n",
    "                        connects to pixels directly up, down, left, right).\n",
    "                      - 2 creates an 8-connected structuring element (square shape: \n",
    "                        connects to all 8 neighboring pixels).\n",
    "                      Using connectivity=2 (8-connectivity) is generally more robust \n",
    "                      for closing various gap orientations and ensuring complete hole filling.\n",
    "\n",
    "    Returns:\n",
    "        A 2D NumPy array where all objects defined by the (now hopefully closed)\n",
    "        white boundaries have their interiors set to True.\n",
    "    \"\"\"\n",
    "    if not isinstance(binary_image_array, np.ndarray):\n",
    "        raise TypeError(\"Input must be a NumPy array.\")\n",
    "    if binary_image_array.ndim != 2:\n",
    "        raise ValueError(\"Input array must be 2-dimensional.\")\n",
    "    if connectivity not in [1, 2]: # Assuming 2D input based on ndim check\n",
    "        raise ValueError(\"Connectivity must be 1 (for 4-way) or 2 (for 8-way) for 2D images.\")\n",
    "\n",
    "    # Ensure the input array is boolean, as required by morphological functions.\n",
    "    # This handles cases where the input might be 0s and 1s instead of True/False.\n",
    "    binary_image_boolean = binary_image_array.astype(bool)\n",
    "\n",
    "    # 1. Attempt to close gaps in the boundaries using morphological closing.\n",
    "    #    A structuring element defines the neighborhood for the operation.\n",
    "    #    - rank = binary_image_boolean.ndim (which is 2 for a 2D image)\n",
    "    #    - connectivity (1 or 2 as per function arg) determines its shape.\n",
    "    structuring_element = generate_binary_structure(rank=binary_image_boolean.ndim, \n",
    "                                                    connectivity=connectivity)\n",
    "    \n",
    "    # Perform binary closing. More iterations close larger gaps.\n",
    "    # border_value=False ensures that operations near the border treat pixels\n",
    "    # outside the image as False, preventing artificial connections to the border.\n",
    "    closed_image = binary_closing(binary_image_boolean, \n",
    "                                  structure=structuring_element, \n",
    "                                  iterations=closing_iterations,\n",
    "                                  border_value=False)\n",
    "\n",
    "    # 2. Fill the holes in the (hopefully) now-closed objects.\n",
    "    #    Using the same structuring element (or at least same connectivity) for\n",
    "    #    hole filling ensures consistency if any fine details of the boundary\n",
    "    #    matter for defining the hole.\n",
    "    filled_image_array = binary_fill_holes(closed_image, \n",
    "                                           structure=structuring_element)\n",
    "    \n",
    "    return filled_image_array"
   ],
   "id": "7e44ef40980ef8cc",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retrieve Region Mask"
   ],
   "id": "9ce8b21ff042d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.153295Z",
     "start_time": "2025-06-21T00:57:10.150789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_region_mask(regions, image=None):\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image must be provided to visualize regions.\")\n",
    "    region_mask = np.zeros_like(image, dtype=bool)\n",
    "    flatten_regions = [pixel for region in regions for pixel in region]\n",
    "    # For each pixel of flatten_regions, set the corresponding pixel in the region_mask to True\n",
    "    for r, c in flatten_regions:\n",
    "        region_mask[r, c] = True\n",
    "    return region_mask"
   ],
   "id": "7fb483ba53f170a5",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cleanup Mask"
   ],
   "id": "1795f55280e7a17a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.164722Z",
     "start_time": "2025-06-21T00:57:10.161723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cleanup_mask(mask, buffer_size=0, print_output=False, image=None, min_object_size=0, min_hole_size=0, try_binary_fill_holes=False):\n",
    "    \"\"\"\n",
    "    This function takes the mask and cleanup by binary filling holes and then cleaning boundaries.\n",
    "    Parameters:\n",
    "        mask: numpy array, the input mask\n",
    "        buffer_size: int, the size of the buffer to clear the border\n",
    "        print_output: bool, whether to print the output or not\n",
    "        image: numpy array, the input image to overlay the mask on (optional)\n",
    "        min_object_size: int, minimum size of objects to keep\n",
    "        min_hole_size: int, minimum size of holes to fill\n",
    "        try_binary_fill_holes: bool, whether to try binary filling holes or not\n",
    "    Returns:\n",
    "        cleared: numpy array, the cleaned mask after filling holes and clearing borders\n",
    "    \"\"\"\n",
    "    # Binary fill holes in the mask to fill any holes inside the regions\n",
    "    if try_binary_fill_holes:\n",
    "        filled_mask = ndimage.binary_fill_holes(mask).astype(bool)\n",
    "    else:\n",
    "        filled_mask = mask\n",
    "    cleared = clear_border(filled_mask, buffer_size=buffer_size)\n",
    "    cleared = remove_small_objects(cleared, min_object_size)\n",
    "    cleared = remove_small_holes(cleared, min_hole_size)\n",
    "\n",
    "    if print_output:\n",
    "        print(f\"Filled mask shape: {filled_mask.shape}, Data type: {filled_mask.dtype}\")\n",
    "        cmap = mcolors.ListedColormap([(0, 0, 0, 0), (1, 1, 1, 1)])  # Transparent black, opaque white\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        if image is not None:\n",
    "            ax.imshow(image, cmap='gray')\n",
    "        ax.imshow(cleared, cmap=cmap, alpha=1.0)  # Overlay the filled mask on the image\n",
    "    return cleared"
   ],
   "id": "d93632d864239dee",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Outputs"
   ],
   "id": "8b364e7b0087d478"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.175661Z",
     "start_time": "2025-06-21T00:57:10.172309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_regions(regions, figsize=(10, 10), image=None):\n",
    "    \"\"\"\n",
    "    Print the regions as overlay of the original image.\n",
    "    :param regions: Regions detected from `scikit-learn` `label` function.\n",
    "    :param figsize: Tuple defining the figsize. Default is (10, 10).\n",
    "    :param image: Image object representing the original image. Default is None.\n",
    "    :return: Numpy array with regions represented as binary.\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image must be provided to visualize regions.\")\n",
    "    # Add a white mask on the regions of interest\n",
    "    region_mask = get_region_mask(regions, image)\n",
    "    print(f\"Number of unique labels found: {len(regions)}\")\n",
    "    colors = [(0, 0, 0, 0), (1, 1, 1, 1)]  # Transparent black, opaque white\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "    ax.imshow(region_mask, cmap=cmap, alpha=1.0) # For the internal regions\n",
    "    # ax.imshow(combined_mask, cmap=cmap, alpha=1.0) # For the boundary\n",
    "    return region_mask"
   ],
   "id": "dd215bdaf4761be8",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.189261Z",
     "start_time": "2025-06-21T00:57:10.185716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_region_boundaries(region_properties, image = None, region_threshold = 0, show_mask = False, mask_image = None):\n",
    "    \"\"\"\n",
    "    Print the regions boundaries as overlay of the original image.\n",
    "    :param region_properties: Regions detected from `scikit-learn` `label` function.\n",
    "    :param image: Image object representing the original image. Default is None.\n",
    "    :param region_threshold: Minimum size of the region to be considered.\n",
    "    :param show_mask: Boolean, whether to show the regions masks.\n",
    "    :param mask_image: Image object representing the region mask. Default is None.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image must be provided to visualize regions.\")\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "    if show_mask and mask_image is not None:\n",
    "        # If a mask image is provided, display it\n",
    "        cmap = mcolors.ListedColormap([(0, 0, 0, 0), (1, 1, 1, 1)])\n",
    "        ax.imshow(mask_image, cmap=cmap, alpha=0.5)  # Overlay the mask on the image\n",
    "    \n",
    "    for region in region_properties:\n",
    "        # take regions with large enough areas\n",
    "        # can adjust\n",
    "        if region.area >= region_threshold:\n",
    "            # draw rectangle around segmented coins\n",
    "            minr, minc, maxr, maxc = region.bbox\n",
    "            rect = mpatches.Rectangle(\n",
    "                (minc, minr),\n",
    "                maxc - minc,\n",
    "                maxr - minr,\n",
    "                fill=False,\n",
    "                edgecolor='red',\n",
    "                linewidth=2,\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "ef2c5a4c86fbd955",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# visualize all the annotations on the image\n",
    "def visualize_annotations(image, annotations):\n",
    "    \"\"\"\n",
    "    Visualize the COCO formated segmentations\n",
    "    :param image: Original image\n",
    "    :param annotations: Annotation object\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation['bbox']\n",
    "        rect = mpatches.Rectangle(\n",
    "            (bbox[0], bbox[1]),\n",
    "            bbox[2],\n",
    "            bbox[3],\n",
    "            fill=False,\n",
    "            edgecolor='red',\n",
    "            linewidth=2,\n",
    "        )\n",
    "        # Create polygon from segmentation\n",
    "        segmentation = annotation['segmentation']\n",
    "        if segmentation:\n",
    "            for seg in segmentation:\n",
    "                poly = mpatches.Polygon(np.array(seg).reshape(-1, 2), closed=True, fill=False, edgecolor='blue',\n",
    "                                        linewidth=1)\n",
    "                ax.add_patch(poly)\n",
    "\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "d550ad1a064d5a64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def mask_to_coco_polygon(mask, image_id, category_id, annotation_id, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Export mask to COCO formatted polygon.\n",
    "    :param mask: Mask of the ROIs generated from the image.\n",
    "    :param image_id: ID of the original image.\n",
    "    :param category_id: Category of the ROIs generated from the image.\n",
    "    :param annotation_id: ID of the annotation of the ROIs generated from the image.\n",
    "    :param image_width: Width of the original image.\n",
    "    :param image_height: Height of the original image.\n",
    "    :return: Array of polygons in COCO format.\n",
    "    \"\"\"\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    segmentations = []\n",
    "    for contour in contours:\n",
    "        # Flatten the contour points and convert to list\n",
    "        segmentation = contour.flatten().tolist()\n",
    "        segmentations.append(segmentation)\n",
    "\n",
    "    # Calculate bounding box (x_min, y_min, width, height)\n",
    "    x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))\n",
    "    bbox = [x, y, w, h]\n",
    "\n",
    "    # Calculate area\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    annotation = {\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": category_id,\n",
    "        \"segmentation\": segmentations,\n",
    "        \"area\": float(area),\n",
    "        \"bbox\": bbox,\n",
    "        \"iscrowd\": 0\n",
    "    }\n",
    "    return annotation"
   ],
   "id": "c01751ce49168058"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading the Image"
   ],
   "id": "8ba6a3d8e453e4ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:10.200425Z",
     "start_time": "2025-06-21T00:57:10.197265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory to the scan images\n",
    "data_path = r'my/data/source'"
   ],
   "id": "d48b4cfb63746814",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Set image\n",
    "image = os.path.join(data_path, 'my_image.png')\n",
    "if not os.path.exists(image):\n",
    "    raise FileNotFoundError(f\"Image not found at {image}\")\n",
    "\n",
    "# Print the image as output\n",
    "print(f\"Image loaded from: {image}\")\n",
    "image = Image.open(image).convert('L')  # Convert to grayscale\n",
    "# Print the image\n",
    "print(f\"Image size: {image.size}, Mode: {image.mode}\")\n",
    "# Convert to numpy array\n",
    "image = np.array(image)\n",
    "# Print the numpy array shape\n",
    "print(f\"Numpy array shape: {image.shape}, Data type: {image.dtype}\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.close()"
   ],
   "id": "f77d2bac88fc87f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Detecting Bounding Boxes"
   ],
   "id": "286d45784adc3bab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create a Binary Mask"
   ],
   "id": "e1cca32d2f763572"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# apply threshold\n",
    "thresh = threshold_otsu(image)\n",
    "bw = closing(image > thresh, footprint_rectangle((5, 5), decomposition='sequence'))\n",
    "\n",
    "# Print the binary image shape\n",
    "print(f\"Binary image shape: {bw.shape}, Data type: {bw.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(bw, cmap='gray')"
   ],
   "id": "2227cbdb204729b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove artifacts connected to image border\n",
    "cleared = cleanup_mask(bw, buffer_size=0, print_output=False, image=image, min_object_size=0, min_hole_size=5)\n",
    "# Print the cleared image shape\n",
    "print(f\"Cleared image shape: {cleared.shape}, Data type: {cleared.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cleared, cmap='gray')"
   ],
   "id": "a358439c64f5643b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Labeling Image Regions"
   ],
   "id": "3dffc1862baa3c1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# label image regions\n",
    "label_image = label(cleared)\n",
    "\n",
    "# Print the number of labels found\n",
    "num_labels = np.max(label_image)\n",
    "print(f\"Number of labels found: {num_labels}\")\n",
    "# Print the labeled image shape\n",
    "print(f\"Labeled image shape: {label_image.shape}, Data type: {label_image.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(label_image, cmap='nipy_spectral')"
   ],
   "id": "a604a5f7b3eaf6b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Draw Bounding Boxes from Regions"
   ],
   "id": "97e9a3aafa37269f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show bounding boxes around the labeled regions.\n",
    "# to make the background transparent, pass the value of `bg_label`,\n",
    "# and leave `bg_color` as `None` and `kind` as `overlay`\n",
    "image_label_overlay = label2rgb(label_image, image=image, bg_label=0, bg_color=None, kind='overlay')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image, cmap='gray')\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    # take regions with large enough areas\n",
    "    # can adjust\n",
    "    if region.area >= 100:\n",
    "        # draw rectangle around segmented coins\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle(\n",
    "            (minc, minr),\n",
    "            maxc - minc,\n",
    "            maxr - minr,\n",
    "            fill=False,\n",
    "            edgecolor='red',\n",
    "            linewidth=2,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c08ad2263036ac15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dilate the Label Mask"
   ],
   "id": "a8ed0fc502d95cb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use dilation to connect gaps in the boundary\n",
    "# dilated_image = cleared.copy()\n",
    "# Dilate the image for 10 times with a rectangular footprint\n",
    "\n",
    "dilated_image = morphology.binary_dilation(cleared, footprint_rectangle((3, 3), decomposition='sequence'))\n",
    "# Print the dilated image shape\n",
    "print(f\"Dilated image shape: {dilated_image.shape}, Data type: {dilated_image.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(dilated_image, cmap='gray')"
   ],
   "id": "e546d82d640f710",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Clear again\n",
    "cleared = cleanup_mask(dilated_image, buffer_size=0, print_output=False, image=image, min_object_size=5, min_hole_size=10)\n",
    "# Print the cleared image shape\n",
    "print(f\"Cleared image shape: {cleared.shape}, Data type: {cleared.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cleared, cmap='gray')"
   ],
   "id": "44c5b204426b1414",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Labeling Image Regions from Dilated Borders"
   ],
   "id": "f1d1e28af5d5b6e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# label image regions\n",
    "label_image = label(cleared)\n",
    "\n",
    "# Print the number of labels found\n",
    "num_labels = np.max(label_image)\n",
    "print(f\"Number of labels found: {num_labels}\")\n",
    "# Print the labeled image shape\n",
    "print(f\"Labeled image shape: {label_image.shape}, Data type: {label_image.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(label_image, cmap='nipy_spectral')"
   ],
   "id": "3a6e5910b259c12a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Draw Bounding Boxes from Regions of Dilated Labels"
   ],
   "id": "e29b7728d25ce17b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# to make the background transparent, pass the value of `bg_label`,\n",
    "# and leave `bg_color` as `None` and `kind` as `overlay`\n",
    "image_label_overlay = label2rgb(label_image, image=image, bg_label=0, bg_color=None, kind='overlay')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image, cmap='gray')\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    # take regions with large enough areas\n",
    "    # can adjust\n",
    "    if region.area >= 100:\n",
    "        # draw rectangle around segmented coins\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle(\n",
    "            (minc, minr),\n",
    "            maxc - minc,\n",
    "            maxr - minr,\n",
    "            fill=False,\n",
    "            edgecolor='red',\n",
    "            linewidth=2,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "51c8531b84999f7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create Mask Around ROIs",
   "id": "243210b5de9f89d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# With the label_image, we can see the boundaries of ROIs. We want to create mask with everything inside the boundaries.\n",
    "# Create a mask for the ROIs\n",
    "mask = np.zeros_like(label_image, dtype=np.uint8)\n",
    "# Fill the mask with the labeled regions\n",
    "for region in regionprops(label_image):\n",
    "    # if region.area >= 100:  # Adjust the area threshold as needed\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    mask[minr:maxr, minc:maxc] = 1  # Fill the mask with 1s for the region\n",
    "\n",
    "# Print the mask shape\n",
    "print(f\"Mask shape: {mask.shape}, Data type: {mask.dtype}\")\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image, cmap='gray')\n",
    "\n",
    "ax.imshow(mask, cmap='gray', alpha=0.3)  # Overlay the mask on the image\n",
    "ax.imshow(label_image, cmap='nipy_spectral', alpha=0.3)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(mask, cmap='gray')"
   ],
   "id": "d88aa200d89b8b49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Try to Fill the Regions\n",
    "We have the boundary of each of the regions. Let's try to fill the regions to generate complete mask."
   ],
   "id": "4c20d6977f0d8b19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Use `binary_fill_holes` to Fill the Mask"
   ],
   "id": "34f8f941f1b75b86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# With the label_image, we can see the boundaries of ROIs. We want to create mask with everything inside the boundaries.\n",
    "# To achieve that we will use fill_holes to fill the empty spaces inside the boundaries.\n",
    "object_masks = {}\n",
    "combined_mask = np.zeros_like(label_image, dtype=bool)\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    if region.area < 100:  # Skip small regions\n",
    "        continue\n",
    "    region_label = region.label\n",
    "    min_row, min_col, max_row, max_col = region.bbox\n",
    "\n",
    "    # Create a blank mask for the entire image\n",
    "    mask = np.zeros_like(label_image, dtype=bool)\n",
    "\n",
    "    # Create a slice of the label image and find mask for current label\n",
    "    region_slice = label_image[min_row:max_row, min_col:max_col]\n",
    "    rows, cols = np.where(region_slice == region_label)\n",
    "\n",
    "    # Offset coordinates to fit the main image\n",
    "    rows += min_row\n",
    "    cols += min_col\n",
    "\n",
    "    # Set the mask inside the bounding box to True where label matches\n",
    "    mask[rows, cols] = True\n",
    "    \n",
    "    # Fill holes in the mask\n",
    "    structure = np.ones((3, 3), dtype=bool) # 3x3 structure works best for filling smaller holes.\n",
    "    filled_mask = ndimage.binary_fill_holes(mask, structure=structure).astype(bool)\n",
    "\n",
    "    object_masks[region_label] = filled_mask\n",
    "    \n",
    "    # Combine the mask with the main mask\n",
    "    combined_mask |= filled_mask\n",
    "    \n",
    "\n",
    "# Print the mask shape\n",
    "print(f\"Mask shape: {combined_mask.shape}, Data type: {combined_mask.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(combined_mask, cmap='gray')"
   ],
   "id": "9a0b7bda1c353b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Number of unique labels found: {len(object_masks)}\")\n",
    "colors = [(0, 0, 0, 0), (1, 1, 1, 1)]  # Transparent black, opaque black\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image, cmap='gray')\n",
    "for object_label, mask in object_masks.items():\n",
    "    ax.imshow(mask, cmap=cmap, alpha=1.0)"
   ],
   "id": "612aeac64bebfb2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Manually Fill the ROIs\n",
    "We'll use the custom functions we wrote to manually try to fill the ROIs."
   ],
   "id": "69959375a7b42b0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regions = find_regions_of_interest(image, combined_mask, tolerance=0)\n",
    "region_mask = print_regions(regions, image=image)"
   ],
   "id": "66b8440f5d4c8b47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# It looks like the first method is the cleanest one for finding regions of interest. Let's visualize the mask.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(region_mask, cmap='gray')"
   ],
   "id": "c1fef1fe73bccf75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Gradually fill the regions\n",
    "We will call the cleanup function multiple times to gradually fill the regions and see how the mask changes. This should go through a trial and error process to find how many times we need to do this. Going through the process too many times often remove ROIs or does not improve results at all."
   ],
   "id": "1942816351ad5ce6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filled_mask = ndimage.binary_fill_holes(region_mask).astype(bool)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(filled_mask, cmap='gray')"
   ],
   "id": "323858a95ee80eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cleaned_mask = cleanup_mask(filled_mask, buffer_size=0, print_output=False, image=image, min_object_size=10, min_hole_size=5, try_binary_fill_holes=True)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cleared, cmap='gray')"
   ],
   "id": "aa06a97524f6f471",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cleaned_mask, cmap='gray')\n",
    "plt.axis('off')"
   ],
   "id": "a80f324226d5f0bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create Bounding Boxes from the Filled Mask"
   ],
   "id": "80cdf6718daf19e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T00:57:55.305467Z",
     "start_time": "2025-06-21T00:57:55.300834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the filled mask to create bounding boxes around the sand grains.\n",
    "label_image = label(cleaned_mask)"
   ],
   "id": "ea382a74c30f5e58",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print the number of labels found\n",
    "num_labels = np.max(label_image)\n",
    "print(f\"Number of labels found: {num_labels}\")\n",
    "# Print the labeled image shape\n",
    "print(f\"Labeled image shape: {label_image.shape}, Data type: {label_image.dtype}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(label_image, cmap='nipy_spectral')"
   ],
   "id": "bc20ed5d28008cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "region_properties = regionprops(label_image)\n",
    "print_region_boundaries(region_properties, image=image, region_threshold=100, show_mask=True, mask_image=cleaned_mask)\n",
    "print_region_boundaries(region_properties, image=image, region_threshold=100, show_mask=False, mask_image=cleaned_mask)"
   ],
   "id": "9d110e32689de6ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T01:35:17.755472Z",
     "start_time": "2025-06-21T01:35:17.747100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contours, _ = cv2.findContours(cleaned_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ],
   "id": "96cc9b50749d00c2",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Create Segmentation in COCO Format from the Bounding Boxes"
   ],
   "id": "19bbff0b6be89b59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T01:54:37.782787Z",
     "start_time": "2025-06-21T01:54:37.764940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "segmentations = []\n",
    "annotations = []\n",
    "for contour in contours:\n",
    "    # Flatten the contour points and convert to list\n",
    "    segmentation = contour.flatten().tolist()\n",
    "    segmentations.append(segmentation)\n",
    "\n",
    "    # Calculate bounding box (x_min, y_min, width, height)\n",
    "    x, y, w, h = cv2.boundingRect(np.array(segmentation).reshape(-1, 2))\n",
    "    bbox = [x, y, w, h]\n",
    "    area = int(w) * int(h)\n",
    "    if area > 10:\n",
    "        annotation = {\n",
    "            \"id\": 1,\n",
    "            \"image_id\": 1,\n",
    "            \"category_id\": 1,\n",
    "            \"segmentation\": segmentations,\n",
    "            \"area\": float(area),\n",
    "            \"bbox\": bbox,\n",
    "            \"iscrowd\": 0\n",
    "        }\n",
    "        annotations.append(annotation)"
   ],
   "id": "962dda28e579f501",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "visualize_annotations(image, annotations)"
   ],
   "id": "8ad50e6e0931b1eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
